{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_alpha = 0.25\n",
    "\n",
    "def set_color(obj, color):\n",
    "    face, txt = obj\n",
    "    face.set_alpha(base_alpha)\n",
    "    face.set_color(color)\n",
    "    txt.set_alpha(1.0)\n",
    "\n",
    "def make_grad(obj):\n",
    "    for o in obj:\n",
    "        set_color(o, 'r')\n",
    "        o[1].set_text('$\\\\nabla$' + o[1].get_text())\n",
    "\n",
    "def hide(obj):\n",
    "    face, txt = obj\n",
    "    face.set_alpha(0.0)\n",
    "    face.set_color('w')\n",
    "    txt.set_alpha(0.0)\n",
    "\n",
    "def show_solid(solid):\n",
    "    for face in solid:\n",
    "        face.set_alpha(0.25)\n",
    "\n",
    "def dim_solid(solid):\n",
    "    for face in solid:\n",
    "        face.set_alpha(0.2)\n",
    "\n",
    "def flash_solid(solids, steps):\n",
    "    for solid in solids:\n",
    "        dim_solid(solid)\n",
    "    yield\n",
    "    for _ in range(steps):\n",
    "        for solid in solids:\n",
    "            show_solid(solid)\n",
    "        yield\n",
    "        for solid in solids:\n",
    "            dim_solid(solid)\n",
    "        yield\n",
    "    for solid in solids:\n",
    "        hide_solid(solid)\n",
    "    yield\n",
    "\n",
    "def hide_solid(solid):\n",
    "    for face in solid:\n",
    "        face.set_alpha(0.0)\n",
    "\n",
    "def fwd(ys, flops):\n",
    "    for f in flops:\n",
    "        show_solid(f)\n",
    "    for y in ys:\n",
    "        set_color(y, 'g')\n",
    "    yield\n",
    "    for f in flops:\n",
    "        hide_solid(f)\n",
    "\n",
    "def bwd_act(xs, flops):\n",
    "    for f in flops:\n",
    "        show_solid(f)\n",
    "    make_grad(xs)\n",
    "    yield\n",
    "    for f in flops:\n",
    "        hide_solid(f)\n",
    "\n",
    "def bwd_weight(ys, w, flops, xs=None):\n",
    "    for i in range(len(ys) + 1):\n",
    "        if i < len(ys):\n",
    "            for f in flops[i]:\n",
    "                show_solid(f)\n",
    "            if i == len(ys) - 1:\n",
    "                make_grad(w)\n",
    "            yield\n",
    "        if i > 0:\n",
    "            for f in flops[i-1]:\n",
    "                hide_solid(f)\n",
    "            for y in ys[i-1]:\n",
    "                hide(y)\n",
    "            if xs is not None:\n",
    "                for x in xs[i-1]:\n",
    "                    hide(x)\n",
    "\n",
    "def make_face(ax, vals1, vals2, depth, dim1, dim2, name=None, color='b', alpha=base_alpha):\n",
    "    dim3 = 3 - dim1 - dim2\n",
    "    val1, val2 = np.meshgrid(vals1, vals2)\n",
    "    val3 = np.full_like(val1, depth)\n",
    "    arg = np.zeros((3, *val1.shape))\n",
    "    arg[[dim1, dim2, dim3]] = val1, val2, val3\n",
    "    face = ax.plot_surface(*arg, color=color, alpha=alpha, linewidth=2, edgecolor=color)\n",
    "    if name is None:\n",
    "        return face\n",
    "    else:\n",
    "        textpos = np.zeros(3)\n",
    "        textpos[[dim1, dim2, dim3]] = np.mean(vals1), np.mean(vals2), depth\n",
    "        txt = ax.text(*textpos, name, color='k', fontsize=10, ha='center', va='center', alpha=(alpha > 0))\n",
    "        return face, txt\n",
    "\n",
    "def make_rectangular_solid(ax, vals, dims, color='y'):\n",
    "    faces = []\n",
    "    for dim_idx in range(3):\n",
    "        other_dims = list({0, 1, 2} - {dim_idx})\n",
    "        for i in range(2):\n",
    "            faces.append(make_face(ax, vals[other_dims[0]], vals[other_dims[1]], vals[dim_idx][i],\n",
    "                                   dims[other_dims[0]], dims[other_dims[1]], None, color=color, alpha=0.0))\n",
    "    return faces\n",
    "\n",
    "def draw_arrow(ax, dimvals, val1s, val2s, label, dim, otherdim1, otherdim2):\n",
    "    tail = np.zeros(3)\n",
    "    vec = np.zeros(3)\n",
    "    tail[[dim, otherdim1, otherdim2]] = dimvals[0], val1s[0], val2s[0]\n",
    "    vec[[dim, otherdim1, otherdim2]] = dimvals[1], 0, 0\n",
    "    ax.quiver(*tail, *vec, color='k', arrow_length_ratio=0.0, linewidth=2)\n",
    "    text_pos = (tail + vec/2)\n",
    "    text_pos[otherdim1] += val1s[1]\n",
    "    text_pos[otherdim2] += val2s[1]\n",
    "    ax.text(*text_pos, label, color='k', fontsize=10, ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/7mk4bf691yx4h91m65gbv_xm0000gn/T/ipykernel_84462/851409900.py:243: UserWarning: frames=<zip object at 0x7fe4d4ce7080> which we can infer the length of, did not pass an explicit *save_count* and passed cache_frame_data=True.  To avoid a possibly unbounded cache, frame data caching has been disabled. To suppress this warning either pass `cache_frame_data=False` or `save_count=MAX_FRAMES`.\n",
      "  ani = FuncAnimation(fig, update, frames=update_gen)\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "d_model = 8\n",
    "d_hidden = 2*d_model\n",
    "B = 48\n",
    "L = 1\n",
    "dp = 1\n",
    "pp = 1\n",
    "tp = 1\n",
    "microbatches = 1#4*pp\n",
    "assert L % pp == 0\n",
    "assert L == 1 or tp == 1\n",
    "pipeline_intvl = L // pp\n",
    "show_compute_blocks = True\n",
    "\n",
    "L_by_hidden_ax = 0\n",
    "B_ax = 1\n",
    "L_by_d_model_ax = 2\n",
    "\n",
    "dp_gpu_delta = 16\n",
    "pp_gpu_delta = 12\n",
    "tp_gpu_delta = 16\n",
    "\n",
    "pp_comm_steps = 2\n",
    "dp_comm_steps = 2\n",
    "tp_comm_steps = 2\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, ax, d_model, d_hidden, tp, B, B_start, B_next_start, wait_for_dp, microbatches, L, pipeline_intvl, show_axes=False):\n",
    "        self.pipeline_intvl = pipeline_intvl\n",
    "        B_end = B_start + B\n",
    "        if B_next_start is not None:\n",
    "            B_next_end = B_next_start + B\n",
    "        self.dp_comms = B_next_start is not None\n",
    "        self.tp_comms = tp > 1\n",
    "        self.wait_for_dp = wait_for_dp\n",
    "        self.microbatches = microbatches\n",
    "\n",
    "        self.residual_activations = []\n",
    "        self.terminal_residual_activations = [[] for _ in range(L//pipeline_intvl)]\n",
    "        self.input_tp_comms = []\n",
    "        self.output_tp_comms = []\n",
    "        self.hidden_activations = []\n",
    "        self.weights1 = []\n",
    "        self.weights2 = []\n",
    "        self.flops1m = []\n",
    "        self.flops2m = []\n",
    "        self.w1_dp_comms = []\n",
    "        self.w2_dp_comms = []\n",
    "        self.pp_comms = [[] for _ in range(L//pipeline_intvl)]\n",
    "\n",
    "        layer_L_by_d_hidden_start = 0\n",
    "        for l in range(L):\n",
    "            # # Alternating\n",
    "            # lz = 0 # z level of hidden\n",
    "            # lzrp = ((l + 1) % 2) - 1 # z bottom of previous residual\n",
    "            # lzr = (l % 2) - 1 # z bottom of residual\n",
    "\n",
    "            # Staircase\n",
    "            lz = -l # z level of hidden\n",
    "            lzrp = -l # z bottom of previous residual\n",
    "            lzr = -l - 1 # z bottom of residual\n",
    "\n",
    "            this_w1_dp_comms = []\n",
    "            this_w2_dp_comms = []\n",
    "            this_weights1 = []\n",
    "            this_weights2 = []\n",
    "            this_hidden_activations = [[] for _ in range(microbatches)]\n",
    "            this_residual_activations = [[] for _ in range(microbatches)]\n",
    "            this_flops1m = [[] for _ in range(microbatches)]\n",
    "            this_flops2m = [[] for _ in range(microbatches)]\n",
    "            this_terminal_residual_activations = [[] for _ in range(microbatches)]\n",
    "            this_input_tp_comms = [[] for _ in range(microbatches)]\n",
    "            this_output_tp_comms = [[] for _ in range(microbatches)]\n",
    "            for tpi in range(tp):\n",
    "                local_layer_L_by_d_hidden_start = layer_L_by_d_hidden_start + tpi * (tp_gpu_delta + d_hidden/tp)\n",
    "                local_layer_L_by_d_hidden_end = local_layer_L_by_d_hidden_start + d_hidden/tp\n",
    "\n",
    "                if l % pipeline_intvl == 0:\n",
    "                    for m in range(microbatches):\n",
    "                        mB_start = B_start + m * (B/microbatches)\n",
    "                        mB_end = mB_start + B/microbatches\n",
    "                        this_terminal_residual_activations[m].append(make_face(ax, (lzrp*d_model, (lzrp+1)*d_model), (mB_start, mB_end),\n",
    "                                                                            local_layer_L_by_d_hidden_start, L_by_d_model_ax, B_ax, f'$x^{{{l-1}}}$', color='g', alpha=0.0))\n",
    "                        if tpi > 0:\n",
    "                            this_input_tp_comms[m].append(make_rectangular_solid(ax, [(local_layer_L_by_d_hidden_start-tp_gpu_delta-d_hidden/tp, local_layer_L_by_d_hidden_start),\n",
    "                                                                                    (lzrp*d_model, (lzrp+1)*d_model), (mB_start, mB_end)],\n",
    "                                                                                    [L_by_hidden_ax, L_by_d_model_ax, B_ax], color='k'))\n",
    "\n",
    "                if self.dp_comms:\n",
    "                    this_w1_dp_comms.append(make_rectangular_solid(ax, [(local_layer_L_by_d_hidden_start, local_layer_L_by_d_hidden_end),\n",
    "                                                                        (lzrp*d_model, (lzrp+1)*d_model), (B_end, B_next_end)],\n",
    "                                                                    [L_by_hidden_ax, L_by_d_model_ax, B_ax], color='k'))\n",
    "                    this_w2_dp_comms.append(make_rectangular_solid(ax, [(local_layer_L_by_d_hidden_start, local_layer_L_by_d_hidden_end),\n",
    "                                                                        (lzr*d_model, (lzr+1)*d_model), (B_end, B_next_end)],\n",
    "                                                                    [L_by_hidden_ax, L_by_d_model_ax, B_ax], color='k'))\n",
    "                this_weights1.append(make_face(ax, (local_layer_L_by_d_hidden_start, local_layer_L_by_d_hidden_end), (lzrp*d_model, (lzrp+1)*d_model),\n",
    "                                                B_end, L_by_hidden_ax, L_by_d_model_ax, f'$W_1^{l}$'))\n",
    "                this_weights2.append(make_face(ax, (local_layer_L_by_d_hidden_start, local_layer_L_by_d_hidden_end), (lzr*d_model, (lzr+1)*d_model),\n",
    "                                                B_end, L_by_hidden_ax, L_by_d_model_ax, f'$W_2^{l}$'))\n",
    "\n",
    "                for m in range(microbatches):\n",
    "                    mB_start = B_start + m * (B/microbatches)\n",
    "                    mB_end = mB_start + B/microbatches\n",
    "                    this_hidden_activations[m].append(make_face(ax, (local_layer_L_by_d_hidden_start, local_layer_L_by_d_hidden_end), (mB_start, mB_end),\n",
    "                                                                lz*d_model, L_by_hidden_ax, B_ax, f'$h^{l}$', color='g', alpha=0.0))\n",
    "                    if tpi > 0:\n",
    "                        this_output_tp_comms[m].append(make_rectangular_solid(ax, [(local_layer_L_by_d_hidden_start-tp_gpu_delta, local_layer_L_by_d_hidden_start+d_hidden/tp),\n",
    "                                                                                (lz*d_model, (lz-1)*d_model), (mB_start, mB_end)],\n",
    "                                                                                [L_by_hidden_ax, L_by_d_model_ax, B_ax], color='k'))\n",
    "                    this_residual_activations[m].append(make_face(ax, (lzr*d_model, (lzr+1)*d_model), (mB_start, mB_end),\n",
    "                                                            local_layer_L_by_d_hidden_start+d_hidden/tp, L_by_d_model_ax, B_ax, f'$x^{l}$', color='g', alpha=0.0))\n",
    "                    if show_compute_blocks:\n",
    "                        this_flops1m[m].append(make_rectangular_solid(ax, [(lzrp*d_model, (lzrp+1)*d_model),\n",
    "                                                                        (local_layer_L_by_d_hidden_start, local_layer_L_by_d_hidden_end), (mB_start, mB_end)],\n",
    "                                                                        [L_by_d_model_ax, L_by_hidden_ax, B_ax]))\n",
    "                        this_flops2m[m].append(make_rectangular_solid(ax, [(lzr*d_model, (lzr+1)*d_model),\n",
    "                                                                            (local_layer_L_by_d_hidden_start, local_layer_L_by_d_hidden_end), (mB_start, mB_end)],\n",
    "                                                                            [L_by_d_model_ax, L_by_hidden_ax, B_ax]))\n",
    "            if l % pipeline_intvl == 0:\n",
    "                self.terminal_residual_activations[l//pipeline_intvl] = this_terminal_residual_activations\n",
    "                self.input_tp_comms.append(this_input_tp_comms)\n",
    "            self.w1_dp_comms.append(this_w1_dp_comms)\n",
    "            self.w2_dp_comms.append(this_w2_dp_comms)\n",
    "            self.weights1.append(this_weights1)\n",
    "            self.weights2.append(this_weights2)\n",
    "            self.hidden_activations.append(this_hidden_activations)\n",
    "            self.output_tp_comms.append(this_output_tp_comms)\n",
    "            self.residual_activations.append(this_residual_activations)\n",
    "            self.flops1m.append(this_flops1m)\n",
    "            self.flops2m.append(this_flops2m)\n",
    "            layer_L_by_d_hidden_start += d_hidden + tp_gpu_delta*(tp-1)\n",
    "            if ((l + 1) % pipeline_intvl == 0) and (l != L - 1):\n",
    "                next_layer_L_by_d_hidden_start = layer_L_by_d_hidden_start + pp_gpu_delta\n",
    "                for m in range(microbatches):\n",
    "                    mB_start = B_start + m * (B/microbatches)\n",
    "                    mB_end = mB_start + B/microbatches\n",
    "                    self.pp_comms[l//pipeline_intvl].append([make_rectangular_solid(ax, [(layer_L_by_d_hidden_start, next_layer_L_by_d_hidden_start),\n",
    "                                                                                        (lzr*d_model, (lzr+1)*d_model), (mB_start, mB_end)],\n",
    "                                                                                    [L_by_hidden_ax, L_by_d_model_ax, B_ax], color='k')])\n",
    "                layer_L_by_d_hidden_start = next_layer_L_by_d_hidden_start\n",
    "\n",
    "        if show_axes:\n",
    "            # draw_arrow(ax, (0, L*d_hidden), (d_model, 3), (B, 3), 'Layer', L_by_hidden_ax, L_by_d_model_ax, B_ax)\n",
    "            draw_arrow(ax, (0, d_hidden/tp), (0, -2), (0, -2), '$d_2$', L_by_hidden_ax, L_by_d_model_ax, B_ax)\n",
    "            draw_arrow(ax, (B_start, B_end), (0, -2), (d_model, 2), 'Batch', B_ax, L_by_hidden_ax, L_by_d_model_ax)\n",
    "            draw_arrow(ax, (0, d_model), (0, -2), (0, -2), '$d_1$', L_by_d_model_ax, L_by_hidden_ax, B_ax)\n",
    "\n",
    "    def microbatch_frame_gen_fwd(self, m, microbatches):\n",
    "        for _ in range(5):\n",
    "            yield\n",
    "        steps_per_stage = 2*self.pipeline_intvl + 1\n",
    "\n",
    "        # Activation fwd pass.\n",
    "        for _ in range(m*steps_per_stage):\n",
    "            yield\n",
    "        for l0 in range(0, L, self.pipeline_intvl):\n",
    "            if l0 > 0:\n",
    "                yield from flash_solid(self.pp_comms[(l0-1)//self.pipeline_intvl][m], pp_comm_steps)\n",
    "            for x in self.terminal_residual_activations[l0//self.pipeline_intvl][m]:\n",
    "                set_color(x, 'g')\n",
    "            if self.tp_comms:\n",
    "                yield from flash_solid(self.input_tp_comms[l0//self.pipeline_intvl][m], tp_comm_steps)\n",
    "            yield\n",
    "            for l in range(l0, l0 + self.pipeline_intvl):\n",
    "                yield from fwd(self.hidden_activations[l][m], self.flops1m[l][m])\n",
    "                yield from fwd(self.residual_activations[l][m], self.flops2m[l][m])\n",
    "                if self.tp_comms:\n",
    "                    yield from flash_solid(self.output_tp_comms[l][m], tp_comm_steps)\n",
    "        for _ in range((microbatches-m-1)*steps_per_stage):\n",
    "            yield\n",
    "        for _ in range(5):\n",
    "            yield\n",
    "\n",
    "    def microbatch_frame_gen_bwd(self, m, microbatches):\n",
    "        # Activation bwd pass.\n",
    "        for _ in range(m*(2*self.pipeline_intvl + 1)):\n",
    "            yield\n",
    "        for l0 in range(L - self.pipeline_intvl, -self.pipeline_intvl, -self.pipeline_intvl):\n",
    "            make_grad(self.residual_activations[l0 + self.pipeline_intvl - 1][m])\n",
    "            if self.tp_comms:\n",
    "                yield from flash_solid(self.output_tp_comms[l0 + self.pipeline_intvl - 1][m], tp_comm_steps)\n",
    "            yield\n",
    "            for l in range(l0 + self.pipeline_intvl - 1, l0, -1):\n",
    "                yield from bwd_act(self.hidden_activations[l][m], self.flops2m[l][m])\n",
    "                if self.tp_comms:\n",
    "                    yield from flash_solid(self.output_tp_comms[l-1][m], tp_comm_steps)\n",
    "                yield from bwd_act(self.residual_activations[l-1][m], self.flops1m[l][m])\n",
    "            yield from bwd_act(self.hidden_activations[l0][m], self.flops2m[l0][m])\n",
    "            yield from bwd_act(self.terminal_residual_activations[l0//self.pipeline_intvl][m], self.flops1m[l0][m])\n",
    "            if self.tp_comms:\n",
    "                yield from flash_solid(self.input_tp_comms[l0//self.pipeline_intvl][m], tp_comm_steps)\n",
    "            if l0 > 0:\n",
    "                yield from flash_solid(self.pp_comms[(l0-1)//self.pipeline_intvl][m], pp_comm_steps)\n",
    "                    \n",
    "        for _ in range((microbatches-m-1)*(2*self.pipeline_intvl + 1)):\n",
    "            yield\n",
    "        yield\n",
    "\n",
    "    def gen_bwd_weight(self, l0):\n",
    "        # Weight bwd pass.\n",
    "        for l in range(l0 + self.pipeline_intvl - 1, l0, -1):\n",
    "            yield from bwd_weight(self.residual_activations[l], self.weights2[l], self.flops2m[l])\n",
    "            yield from bwd_weight(self.hidden_activations[l], self.weights1[l], self.flops1m[l])\n",
    "        yield from bwd_weight(self.residual_activations[l0], self.weights2[l0], self.flops2m[l0])\n",
    "        yield from bwd_weight(self.hidden_activations[l0], self.weights1[l0], self.flops1m[l0], self.terminal_residual_activations[l0//self.pipeline_intvl])\n",
    "        if self.dp_comms:\n",
    "            for l in range(l0 + self.pipeline_intvl - 1, l0 - 1, -1):\n",
    "                yield from flash_solid(self.w1_dp_comms[l], dp_comm_steps)\n",
    "                yield from flash_solid(self.w2_dp_comms[l], dp_comm_steps)\n",
    "        elif self.wait_for_dp:\n",
    "            for _ in range(self.pipeline_intvl*(4*dp_comm_steps + 4)):\n",
    "                yield\n",
    "        for _ in range(15):\n",
    "            yield\n",
    "\n",
    "    def frame_gen(self):\n",
    "        fwd_gen = zip(*[self.microbatch_frame_gen_fwd(m, self.microbatches) for m in range(self.microbatches)])\n",
    "        bwd_act_gen = zip(*[self.microbatch_frame_gen_bwd(m, self.microbatches) for m in range(self.microbatches)])\n",
    "        bwd_weight_gen = zip(*[self.gen_bwd_weight(l0) for l0 in range(0, L, self.pipeline_intvl)])\n",
    "        return it.chain(fwd_gen, bwd_act_gen, bwd_weight_gen)\n",
    "\n",
    "pipelines = []\n",
    "for dpi in range(dp - 1, -1, -1):\n",
    "    pipelines.append(Pipeline(ax, d_model, d_hidden, tp,\n",
    "                              B/dp, dpi*(B/dp+dp_gpu_delta), (dpi+1)*(B/dp+dp_gpu_delta) if dpi < dp - 1 else None,\n",
    "                              dp > 1,\n",
    "                              microbatches,\n",
    "                              L, pipeline_intvl,\n",
    "                              show_axes=(dpi==0)))\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(False)\n",
    "ax.set_xticks([]) \n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "\n",
    "update_gen = zip(*[pipeline.frame_gen() for pipeline in pipelines])\n",
    "def update(_):\n",
    "    return None\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=update_gen)\n",
    "ani.save('batch.mp4', fps=3.75, extra_args=['-vcodec', 'libx264'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
